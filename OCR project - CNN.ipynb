{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc402af",
   "metadata": {},
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f632ae",
   "metadata": {},
   "source": [
    "The aim of this project is to transcript scanned images into text using Deep Learning and Computer Vision techniques.\n",
    "\n",
    "The dataset that I used comes from the following website.\n",
    "You need to create an account to have access to it.\n",
    "\n",
    "The dataset consists of forms, lines and words scanned images. Here, we will only focus on the words images and their labels. These are available in the xml files.\n",
    "\n",
    "Like all data science project, we need to explore and clean our data before applying any DL model on it.\n",
    "In this project, I already preprocessed the data and I focused only on the 100 most frequent words in the dataset.\n",
    "\n",
    "For this project, I decided to run a classification problem using a CNN.\n",
    "\n",
    "With the test set, I obtained an accuracy of 85% but keep in mind that I hugely reduced my dataset. So it could be interesting to see how the model evolves by using all the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b1b2d8",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20048628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D \n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105f6a46",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file in a dataframe\n",
    "\n",
    "data = pd.read_csv('.../top100.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1884a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all the images in a numpy array\n",
    "#Here I put all png files in one folder 'raw'\n",
    "\n",
    "path_images = '.../data/raw'\n",
    "\n",
    "import cv2\n",
    "\n",
    "X = []\n",
    "for img_id in data[\"image_id\"]:\n",
    "    my_image = cv2.imread(path_images + '/' + img_id + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "    my_image = cv2.resize(my_image, dsize = (65,65), interpolation = cv2.INTER_LINEAR)\n",
    "    X.append(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac650d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape inputs and labels so that they can be used for our model\n",
    "\n",
    "X = np.array(X)\n",
    "X = X.reshape([-1,65,65,1])\n",
    "\n",
    "y = data[\"text\"]\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attribute a class for each label\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "enc = preprocessing.OrdinalEncoder(categories='auto')\n",
    "\n",
    "enc.fit(y)\n",
    "\n",
    "target = enc.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size = 0.2)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, dtype = \"int\")\n",
    "y_test = np_utils.to_categorical(y_test, dtype = \"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a5047",
   "metadata": {},
   "source": [
    "# Build the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a80eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "first_layer = Conv2D(filters = 256, kernel_size = (5,5), input_shape = (65,65,1),activation = \"relu\")\n",
    "second_layer = MaxPooling2D(pool_size = (2,2))\n",
    "\n",
    "third_layer = Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\")\n",
    "fourth_layer = MaxPooling2D(pool_size = (2,2))\n",
    "\n",
    "fifth_layer = Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\")\n",
    "sixth_layer = MaxPooling2D(pool_size = (2,2))\n",
    "\n",
    "seventh_layer = Dropout(rate = 0.2)\n",
    "eighth_layer = Flatten()\n",
    "nineth_layer = Dense(units = 128, activation = \"relu\")\n",
    "tenth_layer = Dense(units = y_train.shape[1], activation = \"softmax\")\n",
    "\n",
    "model.add(first_layer)\n",
    "model.add(second_layer)\n",
    "model.add(third_layer)\n",
    "model.add(fourth_layer)\n",
    "model.add(fifth_layer)\n",
    "model.add(sixth_layer)\n",
    "model.add(seventh_layer)\n",
    "model.add(eighth_layer)\n",
    "model.add(nineth_layer)\n",
    "model.add(tenth_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945df97",
   "metadata": {},
   "source": [
    "# Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use callbacks if needed\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "filepath = cwd\n",
    "\n",
    "TON = callbacks.TerminateOnNaN()\n",
    "early_stopping = callbacks.EarlyStopping(monitor = \"val_loss\", patience = 3, mode = \"min\", restore_best_weights = True)\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath = filepath +'/', monitor = \"val_loss\", save_best_only = True, save_weights_only = True, mode = \"min\", save_freq = \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\" , optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fbb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(X_train, y_train, epochs = 5, validation_data = (X_test, y_test), callbacks = [TON, early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a2c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('ocr_model_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d971d021",
   "metadata": {},
   "source": [
    "# Plot losses curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = training_history.history['accuracy']\n",
    "val_acc = training_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0be56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.plot(np.arange(1,6,1), train_acc, label = \"training accuracy\", color = \"blue\")\n",
    "plt.plot(np.arange(1,6,1), val_acc, label = \"validation accuracy\", color = \"green\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70b9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = training_history.history['loss']\n",
    "val_loss = training_history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbd2dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "\n",
    "plt.plot(np.arange(1,6,1), train_loss, label = \"training loss\", color = \"red\")\n",
    "plt.plot(np.arange(1,6,1), val_loss, label = \"validation loss\", color = \"yellow\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace3788e",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3abf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test/1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3267be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_class = test_pred.argmax(axis = 1)\n",
    "y_test_class = y_test.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some results\n",
    "\n",
    "target_new = target.reshape([-1])\n",
    "y_new = y.reshape([-1])\n",
    "\n",
    "j = 1\n",
    "for i in np.random.choice(len(test_pred), size = 3):\n",
    "    img = X_test[i] \n",
    "      \n",
    "    index_test = list(target_new).index(y_test_class[i])\n",
    "    index_pred = list(target_new).index(test_pred_class[i])\n",
    "    \n",
    "    plt.subplot(1, 3, j)\n",
    "    j = j + 1\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=\"gray\", interpolation='None')\n",
    "    plt.title('True Label: ' + str(y_new[index_test]) \\\n",
    "              + '\\n' + 'Prediction: '+ str(y_new[index_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011227fa",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1a0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bdd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the confusion matrix to see where the model got confused\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(test_pred_class,y_test_class)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340f1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test_class, y_test_class)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
